[llm]
api_type = "ollama"
model = "gemma3:4b"
base_url = "http://localhost:11434"
api_key = "ollama"
max_tokens = 4096
temperature = 0.7

[llm.deepseek_ollama]
api_type = "ollama"
model = "deepseek-r1:8b"
base_url = "http://localhost:11434"
api_key = "ollama"
max_tokens = 4096
temperature = 0.7

[llm.deepseek_v3]
api_type = "openai"
model = "deepseek-chat"
base_url = "https://api.deepseek.com/v1"
api_key = "YOUR_API_KEY"
max_tokens = 4096
temperature = 0.7

[llm.deepseek_r1]
api_type = "openai"
model = "deepseek-reasoner"
base_url = "https://api.deepseek.com/v1"
api_key = "YOUR_API_KEY"
max_tokens = 4096
temperature = 0.7

[llm.llama3_2-vision]
api_type = "ollama"
model = "llama3.2-vision:latest"
base_url = "http://localhost:11434"
api_key = "ollama"
max_tokens = 4096
temperature = 0.7
api_version = ""

[llm.gemma3]
api_type = "ollama"
model = "gemma3:4b"
base_url = "http://localhost:11434"
api_key = "ollama"
max_tokens = 4096
temperature = 0.7

[llm.phi4]
api_type = "ollama"
model = "phi4:latest"
base_url = "http://localhost:11434"
api_key = "ollama"
max_tokens = 4096
temperature = 0.7

[llm.qwen3_8b]
api_type = "ollama"
model = "qwen3:8b"
base_url = "http://localhost:11434"
api_key = "ollama"
max_tokens = 4096
temperature = 0.7

[llm.Qwen_siliconflow]
model = "Qwen/QwQ-32B"
base_url = "https://api.siliconflow.cn/v1"
api_key = "YOUR_API_KEY"
max_tokens = 8192   
temperature = 0.0
api_type = "api"

[llm.gpt_4o]
api_type = "openai"
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "YOUR_API_KEY"
max_tokens = 8192
temperature = 0.7

[llm.gpt_3_5_turbo]
api_type = "openai"
model = "gpt-3.5-turbo"
base_url = "https://api.openai.com/v1"
api_key = "YOUR_API_KEY"
max_tokens = 4096
temperature = 0.7

[model_groups]
ollama = [
    { id = "qwen3:8b", name = "Qwen3 8b", config_key = "llm.qwen3_8b" },    
    { id = "gemma3:4b", name = "Gemma3 4b", config_key = "llm.gemma3" },
    { id = "deepseek-r1:8b", name = "DeepSeek R1 8b", config_key = "llm.deepseek_ollama" },
    { id = "phi4", name = "Phi-4", config_key = "llm.phi4" },
    { id = "mistral:latest", name = "Mistral", config_key = "llm.mistral" },    
    { id = "llama3.2-vision", name = "Llama 3.2 Vision", config_key = "llm.llama3_2_vision" }
]

openai = [
    { id = "gpt-4o", name = "GPT-4o", config_key = "llm.gpt_4o" },
    { id = "gpt-3.5-turbo", name = "GPT-3.5 Turbo", config_key = "llm.gpt_3_5_turbo" }
]

deepseek = [
    { id = "deepseek-chat", name = "DeepSeek Chat", config_key = "llm.deepseek_v3" },
    { id = "deepseek-reasoner", name = "DeepSeek-r1", config_key = "llm.deepseek_r1" }
]

siliconflow = [
    { id = "Qwen/QwQ-32B", name = "Qwen-32b", config_key = "llm.Qwen_siliconflow" }
]

[embedding_models]
ollama = [
    { id = "bge-m3:latest", name = "BGE-m3", dimensions = 1024 },
    { id = "BGE-large:latest", name = "BGE-Large", dimensions = 1024 }
]

[vector_databases]
faiss = { name = "FAISS", description = "Facebook AI Similarity Search", local = true }

chroma = { name = "Chroma", description = "Chroma Vector Database", local = true }

[app]
name = "VerseMind-RAG"
version = "1.0.0"
description = "Where Poetry Meets AI"
default_language = "en"



