# VerseMind-RAG 系统使用指南

欢迎使用 VerseMind-RAG 系统，这是一个强大的检索增强生成系统，将向量检索与大语言模型相结合，为您提供基于文档的智能问答服务。

## 系统概述

VerseMind-RAG（Where Poetry Meets AI）是一个模块化的检索增强生成系统，支持以下核心功能：

1. **文档加载**：支持上传和管理 PDF、DOCX、TXT 和 Markdown 文件
2. **文档分块**：使用多种策略将文档分割成适合处理的文本块
3. **文档解析**：分析文档结构，提取段落、标题、表格和图像
4. **向量嵌入**：将文本转换为向量表示，支持多种嵌入模型
5. **向量索引**：构建高效的向量索引，支持 FAISS 和 Chroma 向量数据库
6. **语义搜索**：基于向量相似度进行精准检索
7. **文本生成**：结合检索结果生成连贯、相关的回答

## 快速入门

### 访问系统

系统部署后，您可以通过以下地址访问：

- 前端界面：http://localhost:3000
- API 文档：http://localhost:8000/docs

### 基本工作流程

1. **上传文档**：在"文档加载"模块上传您的文档
2. **文档分块**：选择合适的分块策略处理文档
3. **文档解析**：分析文档结构以提取有意义的内容
4. **创建嵌入**：选择嵌入模型将文本转换为向量
5. **构建索引**：创建向量索引以支持高效检索
6. **执行搜索**：输入查询，系统会返回最相关的文本片段
7. **生成回答**：基于检索结果生成连贯、准确的回答

## 详细功能指南

### 1. 文档加载

在此模块中，您可以：

- 上传 PDF、DOCX、TXT 和 Markdown 文件
- 查看已上传文档列表
- 查看文档详情，包括元数据和预览
- 删除不需要的文档

**使用提示**：对于大型 PDF 文件，系统会自动提取元数据和预览内容。

### 2. 文档分块

在此模块中，您可以选择以下分块策略：

- **按字符数**：固定大小的文本块，适合大多数文档
- **按段落**：以段落为单位分块，保持语义完整性
- **按标题**：根据文档标题结构分块，适合结构化文档

**参数说明**：
- 块大小：每个文本块的目标字符数
- 重叠大小：相邻块之间的重叠字符数，用于保持上下文连贯性

### 3. 文档解析

在此模块中，您可以选择以下解析策略：

- **全文解析**：将整个文档作为一个整体处理
- **分页解析**：按页面组织内容
- **标题结构解析**：根据标题层次结构组织内容

**附加选项**：
- 提取表格：识别和提取文档中的表格
- 提取图像：识别和提取文档中的图像

### 4. 向量嵌入

在此模块中，您可以选择以下嵌入提供商和模型：

- **Ollama**：本地部署的嵌入模型，如 BGE-large
- **OpenAI**：云端 API，如 text-embedding-3-small/large
- **DeepSeek**：替代的云端 API

**使用提示**：本地模型速度更快且无需 API 密钥，但云端模型可能提供更高质量的嵌入。

### 5. 向量索引

在此模块中，您可以选择以下向量数据库：

- **FAISS**：高性能的向量检索库，适合大规模索引
- **Chroma**：开源的向量数据库，支持丰富的元数据

**配置选项**：
- 集合名称：向量数据的逻辑分组
- 索引名称：特定索引的标识符
- 版本：用于跟踪索引更新

### 6. 语义搜索

在此模块中，您可以：

- 选择要查询的索引
- 输入自然语言查询
- 调整搜索参数

**搜索参数**：
- Top K：返回的最相关结果数量
- 相似度阈值：结果必须达到的最小相似度分数
- 最小字符数：结果必须包含的最小字符数

### 7. 文本生成

在此模块中，您可以：

- 基于搜索结果生成回答
- 选择不同的生成模型
- 调整生成参数

**生成模型选项**：
- **Ollama**：本地模型如 llama3、gemma3、phi4 等
- **OpenAI**：云端模型如 GPT-4o、GPT-4-turbo 等
- **DeepSeek**：替代的云端模型

**生成参数**：
- 温度：控制输出的随机性（较低值产生更确定性的输出）
- 最大令牌数：生成文本的最大长度

## 最佳实践

1. **文档准备**：
   - 确保 PDF 文档是可搜索的（非扫描版本）
   - 对于复杂格式的文档，考虑先转换为纯文本

2. **分块策略**：
   - 对于一般文档，使用 1000-1500 字符的块大小和 200 字符的重叠
   - 对于结构化文档，使用按标题分块可能效果更好

3. **嵌入模型选择**：
   - 对于中文文档，BGE-large 模型表现良好
   - 对于英文文档，OpenAI 的嵌入模型通常效果更好

4. **搜索优化**：
   - 从较高的相似度阈值开始（如 0.7），然后根据需要降低
   - 使用具体、明确的查询获得更精确的结果

5. **生成优化**：
   - 对于事实性回答，使用较低的温度值（0.1-0.3）
   - 对于创意内容，使用较高的温度值（0.7-0.9）

## 故障排除

如果您遇到问题，请参考以下常见问题解决方案：

1. **文档上传失败**：
   - 检查文件格式是否支持
   - 确保文件大小在合理范围内（通常<100MB）

2. **分块或解析错误**：
   - 对于复杂格式的文档，尝试不同的分块策略
   - 检查文档是否包含特殊字符或格式

3. **嵌入生成失败**：
   - 确保选择的嵌入模型已正确加载
   - 对于 OpenAI，检查 API 密钥是否有效

4. **搜索结果不相关**：
   - 尝试降低相似度阈值
   - 重新表述查询，使用更具体的术语

5. **生成内容质量低**：
   - 尝试不同的生成模型
   - 调整温度和最大令牌数参数
   - 确保搜索结果与查询相关

## 进阶功能

### 批量处理

对于需要处理大量文档的场景，您可以：

1. 创建一个包含多个文档的目录
2. 使用批量上传功能一次性处理所有文档
3. 为所有文档创建统一的索引

### 自定义模型

高级用户可以：

1. 在 Ollama 中添加自定义模型
2. 修改系统配置以使用这些模型
3. 根据特定领域需求优化模型参数

## 联系与支持

如需进一步帮助或报告问题，请联系系统管理员或参考部署文档中的故障排除部分。
